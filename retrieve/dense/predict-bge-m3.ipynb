{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12587869,"sourceType":"datasetVersion","datasetId":7897854},{"sourceId":12592600,"sourceType":"datasetVersion","datasetId":7927723},{"sourceId":490829,"sourceType":"modelInstanceVersion","modelInstanceId":390289,"modelId":409105}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # --- 0. CÀI ĐẶT & THƯ VIỆN ---\n!pip install -q transformers sentence-transformers faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T02:52:05.582843Z","iopub.execute_input":"2025-07-28T02:52:05.583058Z","iopub.status.idle":"2025-07-28T02:53:32.390823Z","shell.execute_reply.started":"2025-07-28T02:52:05.583032Z","shell.execute_reply":"2025-07-28T02:53:32.389867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport pickle\nimport faiss\n\n# === Đường dẫn (đổi theo dự án của bạn) ===\nPATH_INDEX = \"/kaggle/input/bge-bin/bge_origin\"       # index đã build sẵn\nPATH_CHUNK = \"/kaggle/input/test-vlsp/chunk_corpus.json\"  # corpus gốc\nOUT_META   = \"/kaggle/working/corpus_meta.pkl\"        # nơi lưu meta mới\n\n# 1) Load FAISS index để biết total vectors\nindex = faiss.read_index(PATH_INDEX)\nN = index.ntotal\nprint(\"Index vectors:\", N)\n\n# 2) Load corpus (đảm bảo đúng thứ tự khi build index)\nwith open(PATH_CHUNK, \"r\", encoding=\"utf-8\") as f:\n    chunk_data = json.load(f)\n\n# 3) Build meta\nmeta = []\nfor i, item in enumerate(chunk_data):\n    # Bắt buộc phải có hai trường này\n    if \"aid\" not in item or \"chunk_id\" not in item:\n        raise ValueError(f\"Item thứ {i} thiếu 'aid' hoặc 'chunk_id'\")\n    aid = item[\"aid\"]\n    cid = item[\"chunk_id\"]\n    meta.append((aid, cid))\n\nprint(\"Meta entries:\", len(meta))\n\n# 4) Kiểm tra khớp số lượng\nif len(meta) != N:\n    raise ValueError(\n        f\"Meta length ({len(meta)}) khác index.ntotal ({N}). \"\n        \"Hãy kiểm tra lại thứ tự hoặc số chunk trong corpus.\"\n    )\n\n# 5) Lưu corpus_meta.pkl\nwith open(OUT_META, \"wb\") as f:\n    pickle.dump(meta, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nprint(f\"✅ Đã lưu meta vào {OUT_META}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-28T02:54:16.046585Z","iopub.execute_input":"2025-07-28T02:54:16.047140Z","iopub.status.idle":"2025-07-28T02:54:26.640544Z","shell.execute_reply.started":"2025-07-28T02:54:16.047107Z","shell.execute_reply":"2025-07-28T02:54:26.639784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nimport faiss\nimport pickle\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\nTOPK = 100\n\n# ====== 1️⃣ Load file public test ======\nwith open(\"/kaggle/input/test-vlsp/test.json\", \"r\", encoding=\"utf-8\") as f:\n    queries = json.load(f)\n\n# ====== 2️⃣ Load FAISS index và metadata ======\nindex = faiss.read_index(\"/kaggle/input/bge-bin/bge_origin\")\nwith open(\"/kaggle/working/corpus_meta.pkl\", \"rb\") as f:\n    meta = pickle.load(f)  # [(aid, chunk_id), ...]\n\n# ====== 3️⃣ Load model BGE M3 ======\nmodel = SentenceTransformer(\"/kaggle/input/bge-m3/pytorch/default/1/checkpoint-560\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n\n# ====== 4️⃣ Encode và search, xây dựng cấu trúc JSON ======\noutput = []\nfor q in queries:\n    qid = q[\"qid\"]\n    question = q[\"question\"]\n\n    # Encode query\n    q_emb = model.encode(question, normalize_embeddings=True, convert_to_numpy=True)\n\n    # Search top-100\n    D, I = index.search(np.array([q_emb]), k=TOPK)\n\n    # Chuyển thành list các dict {\"chunk_id\": ..., \"score\": ...}\n    top_chunks = [\n        {\"chunk_id\": meta[idx][1], \"score\": float(D[0][i])}\n        for i, idx in enumerate(I[0])\n    ]\n\n    output.append({\n        \"qid\": qid,\n        \"top_chunks\": top_chunks\n    })\n\n# ====== 5️⃣ Lưu kết quả ra file JSON ======\nwith open(\"bge_v0_results.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(output, f, ensure_ascii=False, indent=2)\n\nprint(\"✅ Đã lưu kết quả\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T03:17:13.727127Z","iopub.execute_input":"2025-07-28T03:17:13.727507Z","iopub.status.idle":"2025-07-28T03:18:15.129173Z","shell.execute_reply.started":"2025-07-28T03:17:13.727480Z","shell.execute_reply":"2025-07-28T03:18:15.128224Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null}]}