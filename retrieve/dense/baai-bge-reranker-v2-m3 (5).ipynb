{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12504473,"sourceType":"datasetVersion","datasetId":7891595}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -U FlagEmbedding[finetune]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:36:07.571449Z","iopub.execute_input":"2025-07-22T14:36:07.571752Z","iopub.status.idle":"2025-07-22T14:38:00.395473Z","shell.execute_reply.started":"2025-07-22T14:36:07.571720Z","shell.execute_reply":"2025-07-22T14:38:00.394711Z"}},"outputs":[{"name":"stdout","text":"Collecting FlagEmbedding[finetune]\n  Downloading FlagEmbedding-1.3.5.tar.gz (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (2.6.0+cu124)\nRequirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (4.52.4)\nRequirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (3.6.0)\nRequirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (1.8.1)\nRequirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (4.1.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (0.15.2)\nCollecting ir-datasets (from FlagEmbedding[finetune])\n  Downloading ir_datasets-0.5.11-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding[finetune]) (3.20.3)\nCollecting deepspeed (from FlagEmbedding[finetune])\n  Downloading deepspeed-0.17.2.tar.gz (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting flash-attn (from FlagEmbedding[finetune])\n  Downloading flash_attn-2.8.1.tar.gz (8.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding[finetune]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding[finetune]) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding[finetune]) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding[finetune]) (6.0.2)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding[finetune]) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding[finetune]) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding[finetune]) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune])\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->FlagEmbedding[finetune])\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding[finetune]) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->FlagEmbedding[finetune]) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.44.2->FlagEmbedding[finetune]) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.44.2->FlagEmbedding[finetune]) (0.21.2)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding[finetune]) (0.8.1)\nCollecting hjson (from deepspeed->FlagEmbedding[finetune])\n  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding[finetune]) (1.1.1)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding[finetune]) (1.11.1.4)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding[finetune]) (9.0.0)\nRequirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding[finetune]) (2.11.7)\nRequirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding[finetune]) (12.575.51)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->FlagEmbedding[finetune]) (4.13.4)\nCollecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->FlagEmbedding[finetune]) (5.4.0)\nCollecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nCollecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\nCollecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding[finetune])\n  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding[finetune]) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding[finetune]) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding[finetune]) (11.2.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding[finetune]) (2.7)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (3.12.13)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.20.1->FlagEmbedding[finetune]) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed->FlagEmbedding[finetune]) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed->FlagEmbedding[finetune]) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed->FlagEmbedding[finetune]) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding[finetune]) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding[finetune]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding[finetune]) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding[finetune]) (2025.6.15)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding[finetune])\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding[finetune]) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding[finetune]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding[finetune]) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding[finetune]) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding[finetune]) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding[finetune]) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding[finetune]) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19.0->FlagEmbedding[finetune]) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding[finetune]) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ir_datasets-0.5.11-py3-none-any.whl (866 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.1/866.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\nDownloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\nDownloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: deepspeed, FlagEmbedding, flash-attn, warc3-wet-clueweb09, cbor\n  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for deepspeed: filename=deepspeed-0.17.2-py3-none-any.whl size=1699826 sha256=f0cc72d419c62b17c956ea3964ee05e634ecffd2ae4c74858738cadd2081e238\n  Stored in directory: /root/.cache/pip/wheels/9b/f1/3d/2854f784c6d04f0450ba02a8fe19399e2fbad4fd6c4758e525\n  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.5-py3-none-any.whl size=233746 sha256=8d7ab80b6ffba6a6e4c15cd642bf5ce6a22aa09ee8b6e3e0a08932fa2ba0833b\n  Stored in directory: /root/.cache/pip/wheels/fc/1c/66/c9c846a8f8cbd9574db8d76b0a61410a087bc07d53682a54f4\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for flash-attn: filename=flash_attn-2.8.1-cp311-cp311-linux_x86_64.whl size=126118408 sha256=5a330e5038acaa2309550110731ba580953f76d445a02d9b0d88906d97831db1\n  Stored in directory: /root/.cache/pip/wheels/fe/e8/f9/c737fa70cd4a4c0cf9f0d7e3b08b669b69893e7a1591919214\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=139cd9e765def998b232dca075633185a3871bed17392770ce0ea3dfe2746ba0\n  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53931 sha256=2481e47d4962eaa4670d64b58db4cccebb6fb97f4acd56d030eb7aa759fddf45\n  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\nSuccessfully built deepspeed FlagEmbedding flash-attn warc3-wet-clueweb09 cbor\nInstalling collected packages: warc3-wet-clueweb09, warc3-wet, hjson, cbor, zlib-state, unlzw3, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lz4, ijson, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, inscriptis, nvidia-cusolver-cu12, flash-attn, trec-car-tools, ir-datasets, FlagEmbedding, deepspeed\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed FlagEmbedding-1.3.5 cbor-1.0.0 deepspeed-0.17.2 flash-attn-2.8.1 fsspec-2025.3.0 hjson-3.1.0 ijson-3.4.0 inscriptis-2.6.0 ir-datasets-0.5.11 lz4-4.4.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Fine-tune","metadata":{}},{"cell_type":"markdown","source":"Below are the arguments for fine-tuning:\n\nThe following arguments are for model:\n- `model_name_or_path`: The model checkpoint for initialization.\n- `config_name`: Pretrained config name or path if not the same as model_name.\n- `tokenizer_name`: Pretrained tokenizer name or path if not the same as model_name.\n- `cache_dir`: Where do you want to store the pre-trained models downloaded from s3.\n- `trust_remote_code`: Trust remote code\n- `token`: The token to use when accessing the model.\n\nThe following arguments are for data:\n- `train_data`: One or more paths to training data. `query: str`, `pos: List[str]`, `neg: List[str]` are required in the training data. Argument type: multiple.\n- `cache_path`: Where do you want to store the cached data.\n- `train_group_size`: (No metadata provided)\n- `query_max_len`: The maximum total input sequence length after tokenization for passage. Sequences longer than this will be truncated.\n- `passage_max_len`: The maximum total input sequence length after tokenization for passage. Sequences longer than this will be truncated.\n- `pad_to_multiple_of`: If set will pad the sequence to be a multiple of the provided value.\n- `max_example_num_per_dataset`: The max number of examples for each dataset.\n- `query_instruction_for_retrieval`: Instruction for query.\n- `query_instruction_format`: Format for query instruction.\n- `knowledge_distillation`: Use knowledge distillation when `pos_scores: List[float]` and `neg_scores: List[float]` are in features of training data.\n- `passage_instruction_for_retrieval`: Instruction for passage.\n- `passage_instruction_format`: Format for passage instruction.\n- `shuffle_ratio`: The ratio of shuffling the text.\n- `same_dataset_within_batch`: All samples in the same batch comes from the same dataset.\n- `small_threshold`: The threshold of small dataset. All small dataset in the same directory will be merged into one dataset.\n- `drop_threshold`: The threshold for dropping merged small dataset. If the number of examples in the merged small dataset is less than this threshold, it will be dropped.\n\nAnd the following extra arguments:\n- `negatives_cross_device`: Share negatives across devices.\n- `temperature`: Temperature used for similarity score.\n- `fix_position_embedding`: Freeze the parameters of position embeddings.\n- `sentence_pooling_method`: The pooling method. Available options: cls, mean, last_token. Default: cls.\n- `normalize_embeddings`: Whether to normalize the embeddings.\n- `sub_batch_size`: Sub batch size for training.\n- `kd_loss_type`: The loss type for knowledge distillation. Available options: kl_div, m3_kd_loss. Default: kl_div.","metadata":{}},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"5075b85e4e708e828d33dba7fcc413dcdecbe4c8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:00.396754Z","iopub.execute_input":"2025-07-22T14:38:00.397035Z","iopub.status.idle":"2025-07-22T14:38:08.429979Z","shell.execute_reply.started":"2025-07-22T14:38:00.397010Z","shell.execute_reply":"2025-07-22T14:38:08.429316Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtringo1507\u001b[0m (\u001b[33mtringooo\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# 1) Gỡ sạch flash-attn\n!pip uninstall -y flash-attn\n\n# 2) Thiết biến môi trường để tắt import Flash-Attention\n%env HF_NO_FLASH_ATTN=1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:08.430774Z","iopub.execute_input":"2025-07-22T14:38:08.431436Z","iopub.status.idle":"2025-07-22T14:38:20.107686Z","shell.execute_reply.started":"2025-07-22T14:38:08.431417Z","shell.execute_reply":"2025-07-22T14:38:20.106791Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: flash_attn 2.8.1\nUninstalling flash_attn-2.8.1:\n  Successfully uninstalled flash_attn-2.8.1\nenv: HF_NO_FLASH_ATTN=1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%bash\ntorchrun --nproc_per_node 2 \\\n  -m FlagEmbedding.finetune.reranker.encoder_only.base \\\n  --model_name_or_path BAAI/bge-reranker-v2-m3 \\\n  --cache_dir /kaggle/working/cache/model \\\n  --train_data /kaggle/input/ft-data/training.json \\\n  --cache_path /kaggle/working/cache/data \\\n  --train_group_size 12 \\\n  --query_max_len 512 \\\n  --passage_max_len 1024 \\\n  --pad_to_multiple_of 8 \\\n  --query_instruction_for_rerank 'Với vai trò là một chuyên gia pháp luật, hãy tìm kiếm các điều khoản, quy định pháp luật có liên quan trực tiếp đến vấn đề: ' \\\n  --query_instruction_format '{}{}' \\\n  --knowledge_distillation False \\\n  --output_dir test_encoder_only_base_bge-reranker-v2-m3 \\\n  --overwrite_output_dir \\\n  --learning_rate 1e-5 \\\n  --bf16 \\\n  --num_train_epochs 20 \\\n  --per_device_train_batch_size 4 \\\n  --gradient_accumulation_steps 16 \\\n  --dataloader_drop_last True \\\n  --warmup_ratio 0.1 \\\n  --deepspeed /kaggle/input/ft-data/ds_stage0.json \\\n  --logging_steps 1 \\\n  --save_steps 500 \\\n  --gradient_checkpointing \\\n  --save_total_limit 3 \\\n  --report_to wandb \\\n  --run_name \"finetune-bge-$(date +%Y%m%d_%H%M)\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T15:03:03.638055Z","iopub.execute_input":"2025-07-22T15:03:03.638673Z","iopub.status.idle":"2025-07-22T15:05:32.281516Z","shell.execute_reply.started":"2025-07-22T15:03:03.638641Z","shell.execute_reply":"2025-07-22T15:05:32.280683Z"}},"outputs":[{"name":"stdout","text":"Process is terminated.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ! pip install -U datasets pytrec_eval FlagEmbedding\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.138639Z","iopub.status.idle":"2025-07-22T14:38:50.138852Z","shell.execute_reply.started":"2025-07-22T14:38:50.138753Z","shell.execute_reply":"2025-07-22T14:38:50.138762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from datasets import load_dataset\n\n# queries = load_dataset(\"json\", data_files=\"/kaggle/input/ft-data/test_queries.jsonl\")[\"train\"]\n# corpus = load_dataset(\"json\", data_files=\"/kaggle/input/ft-data/corpus.jsonl\")[\"train\"]\n# qrels = load_dataset(\"json\", data_files=\"/kaggle/input/ft-data/test_qrels.jsonl\")[\"train\"]\n\n# queries_text = queries[\"text\"]\n# corpus_text = [text for sub in corpus[\"text\"] for text in sub]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.139443Z","iopub.status.idle":"2025-07-22T14:38:50.139644Z","shell.execute_reply.started":"2025-07-22T14:38:50.139548Z","shell.execute_reply":"2025-07-22T14:38:50.139557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# qrels_dict = {}\n# for line in qrels:\n#     if line['qid'] not in qrels_dict:\n#         qrels_dict[line['qid']] = {}\n#     qrels_dict[line['qid']][line['docid']] = line['relevance']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.140832Z","iopub.status.idle":"2025-07-22T14:38:50.141089Z","shell.execute_reply.started":"2025-07-22T14:38:50.140970Z","shell.execute_reply":"2025-07-22T14:38:50.140983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.142352Z","iopub.status.idle":"2025-07-22T14:38:50.142650Z","shell.execute_reply.started":"2025-07-22T14:38:50.142500Z","shell.execute_reply":"2025-07-22T14:38:50.142515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import faiss\n# import numpy as np\n# from tqdm import tqdm\n\n\n# def search(model, queries_text, corpus_text):\n    \n#     queries_embeddings = model.encode_queries(queries_text)\n#     corpus_embeddings = model.encode_corpus(corpus_text)\n    \n#     # create and store the embeddings in a Faiss index\n#     dim = corpus_embeddings.shape[-1]\n#     index = faiss.index_factory(dim, 'Flat', faiss.METRIC_INNER_PRODUCT)\n#     corpus_embeddings = corpus_embeddings.astype(np.float32)\n#     index.train(corpus_embeddings)\n#     index.add(corpus_embeddings)\n    \n#     query_size = len(queries_embeddings)\n\n#     all_scores = []\n#     all_indices = []\n\n#     # search top 100 answers for all the queries\n#     for i in tqdm(range(0, query_size, 32), desc=\"Searching\"):\n#         j = min(i + 32, query_size)\n#         query_embedding = queries_embeddings[i: j]\n#         score, indice = index.search(query_embedding.astype(np.float32), k=100)\n#         all_scores.append(score)\n#         all_indices.append(indice)\n\n#     all_scores = np.concatenate(all_scores, axis=0)\n#     all_indices = np.concatenate(all_indices, axis=0)\n    \n#     # store the results into the format for evaluation\n#     results = {}\n#     for idx, (scores, indices) in enumerate(zip(all_scores, all_indices)):\n#         results[queries[\"id\"][idx]] = {}\n#         for score, index in zip(scores, indices):\n#             if index != -1:\n#                 results[queries[\"id\"][idx]][corpus[\"id\"][index]] = float(score)\n                \n#     return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.143364Z","iopub.status.idle":"2025-07-22T14:38:50.143664Z","shell.execute_reply.started":"2025-07-22T14:38:50.143514Z","shell.execute_reply":"2025-07-22T14:38:50.143528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from FlagEmbedding.abc.evaluation.utils import evaluate_metrics, evaluate_mrr\n# from FlagEmbedding import FlagModel\n\n# k_values = [10,100]\n\n# raw_name = \"BAAI/bge-reranker-v2-m3\"\n# finetuned_path = \"/kaggle/working/test_encoder_only_base_bge-reranker-v2-m3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.145297Z","iopub.status.idle":"2025-07-22T14:38:50.145509Z","shell.execute_reply.started":"2025-07-22T14:38:50.145413Z","shell.execute_reply":"2025-07-22T14:38:50.145422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# raw_model = FlagModel(\n#     raw_name, \n#     query_instruction_for_retrieval=\"Với vai trò là một chuyên gia pháp luật, hãy tìm kiếm các điều khoản, quy định pháp luật có liên quan trực tiếp đến vấn đề: \",\n#     devices=[0],\n#     use_fp16=False\n# )\n\n# results = search(raw_model, queries_text, corpus_text)\n\n# eval_res = evaluate_metrics(qrels_dict, results, k_values)\n# mrr = evaluate_mrr(qrels_dict, results, k_values)\n\n# for res in eval_res:\n#     print(res)\n# print(mrr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.146648Z","iopub.status.idle":"2025-07-22T14:38:50.146928Z","shell.execute_reply.started":"2025-07-22T14:38:50.146761Z","shell.execute_reply":"2025-07-22T14:38:50.146773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ft_model = FlagModel(\n#     finetuned_path, \n#     query_instruction_for_retrieval=\"Với vai trò là một chuyên gia pháp luật, hãy tìm kiếm các điều khoản, quy định pháp luật có liên quan trực tiếp đến vấn đề: \",\n#     devices=[0],\n#     use_fp16=False\n# )\n\n# results = search(ft_model, queries_text, corpus_text)\n\n# eval_res = evaluate_metrics(qrels_dict, results, k_values)\n# mrr = evaluate_mrr(qrels_dict, results, k_values)\n\n# for res in eval_res:\n#     print(res)\n# print(mrr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T14:38:50.148284Z","iopub.status.idle":"2025-07-22T14:38:50.148650Z","shell.execute_reply.started":"2025-07-22T14:38:50.148429Z","shell.execute_reply":"2025-07-22T14:38:50.148441Z"}},"outputs":[],"execution_count":null}]}